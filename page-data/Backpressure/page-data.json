{"componentChunkName":"component---src-templates-blog-post-js","path":"/Backpressure/","result":{"data":{"site":{"siteMetadata":{"title":"lqs469","author":"Qinshuo(Allen) Li"}},"markdownRemark":{"id":"1d948a28-f473-5a2e-93ef-42571889c223","excerpt":"原文 数据处理过程中经常出现一个称为背压(backpressure)的常见问题，用来描述数据传输过程中缓冲区后面的数据累积。当传送的接收端操作复杂时，或者由于某种原因而较慢时，来自传入源的数据有积聚的趋势，如堵塞。 为了解决这个问题，必须有一个授权系统来确保从一个源到另一个源的数据的平滑流动。不同的社区有根据其程序特点的独特解决方案，Unix pipes 和 TCP sockets…","html":"<p><a href=\"https://nodejs.org/en/docs/guides/backpressuring-in-streams/\">原文</a></p>\n<p>数据处理过程中经常出现一个称为<strong>背压(backpressure)</strong>的常见问题，用来描述数据传输过程中缓冲区后面的数据累积。当传送的接收端操作复杂时，或者由于某种原因而较慢时，来自传入源的数据有积聚的趋势，如堵塞。</p>\n<p>为了解决这个问题，必须有一个授权系统来确保从一个源到另一个源的数据的平滑流动。不同的社区有根据其程序特点的独特解决方案，Unix pipes 和 TCP sockets 就是这方面的很好的例子，并且通常被称为流量控制。在Node.js中，Stream 是已被采用的解决方案。</p>\n<p>本指南的目的是进一步详细说明背压是什么，以及流如何在Node.js的源代码中解决这个问题。本指南的第二部分将介绍建议的最佳实践，以确保您的应用程序的代码在实现流时安全和优化。</p>\n<p>我们假设身为读者的你对 Node.js 中背压，<code class=\"language-text\">Buffer</code> 和 <code class=\"language-text\">EventEmitters</code> 的一般定义以及 Stream 的一些经验有点熟悉。如果您还没有阅读这些文档，首先查看API文档并不是一个坏主意，因为这将有助于在阅读本指南时扩展您的理解。</p>\n<h2>数据处理的问题</h2>\n<p>在计算机系统中，数据通过管道，套接字和信号(pipes, sockets, and signals)从一个进程传输到另一个进程。在 Node.js 中，我们找到了一个名为 Stream 的类似机制。Stream 很棒！他们为 Node.js 做了很多工作，几乎内部代码库的每个部分都利用该模块。作为一名开发人员，鼓励您去使用它们！</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token keyword\">const</span> readline <span class=\"token operator\">=</span> <span class=\"token function\">require</span><span class=\"token punctuation\">(</span><span class=\"token string\">'readline'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// process.stdin and process.stdout are both instances of Streams</span>\n<span class=\"token keyword\">const</span> rl <span class=\"token operator\">=</span> readline<span class=\"token punctuation\">.</span><span class=\"token function\">createInterface</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n  input<span class=\"token operator\">:</span> process<span class=\"token punctuation\">.</span>stdin<span class=\"token punctuation\">,</span>\n  output<span class=\"token operator\">:</span> process<span class=\"token punctuation\">.</span>stdout\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nrl<span class=\"token punctuation\">.</span><span class=\"token function\">question</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Why should you use streams? '</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">answer</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  console<span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span><span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token string\">Maybe it's </span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>answer<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token string\">, maybe it's because they are awesome! :)</span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  rl<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>通过比较 Node.js Stream 实现的内部系统工具，可以证明为什么通过 <strong>Stream</strong> 实现 <strong>backpressure</strong> 机制是一个很好的优化。</p>\n<p>在一种情况下，我们将采用大文件(大约9GB) 并使用熟悉的<code class=\"language-text\">zip(1)</code>工具对其进行压缩。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ zip The.Matrix.1080p.mkv</code></pre></div>\n<p>虽然这需要几分钟的时间才能完成，在另一个shell中，我们可以运行一个采用 Node.js 的模块 <code class=\"language-text\">zlib</code> 的脚本，该脚本包含另一个压缩工具 <code class=\"language-text\">gzip(1)</code>。</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token keyword\">const</span> gzip <span class=\"token operator\">=</span> <span class=\"token function\">require</span><span class=\"token punctuation\">(</span><span class=\"token string\">'zlib'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">createGzip</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> fs <span class=\"token operator\">=</span> <span class=\"token function\">require</span><span class=\"token punctuation\">(</span><span class=\"token string\">'fs'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> inp <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createReadStream</span><span class=\"token punctuation\">(</span><span class=\"token string\">'The.Matrix.1080p.mkv'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> out <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createWriteStream</span><span class=\"token punctuation\">(</span><span class=\"token string\">'The.Matrix.1080p.mkv.gz'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\ninp<span class=\"token punctuation\">.</span><span class=\"token function\">pipe</span><span class=\"token punctuation\">(</span>gzip<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">pipe</span><span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>然后来验证结果，尝试打开每个压缩文件。由 <code class=\"language-text\">zip(1)</code> 工具压缩的文件将通知您文件已损坏，而由 Stream 完成的压缩将无错地解压缩。</p>\n<p>注意：在本例中，我们使用 <code class=\"language-text\">.pipe()</code> 从一端到另一端获取数据源。但是，请注意，没有附加适当的错误处理程序。如果大量数据无法正确接收，则可读源或 <code class=\"language-text\">gzip</code> 流不会被销毁。<code class=\"language-text\">.pump</code> 是一个很实用工具，如果其中一个失败或关闭，它将稳定无误地销毁管道中的所有流，并且在这种情况下是必须的！</p>\n<h2>数据太多, 太快</h2>\n<p>有些情况下，可读流可能太快地将数据提供给<code class=\"language-text\">Writable</code> - 远远超过消费者可以处理的数量！</p>\n<p>当发生这种情况时，消费者将开始排列所有数据块以供以后使用。写入队列将变得越来越长，并且因为这个更多的数据必须保存在内存中，直到整个过程完成。</p>\n<p>写入磁盘比从磁盘读取要慢很多，因此，当我们试图压缩文件并将其写入硬盘时，就会发生背压，因为写入磁盘将无法跟上速度阅读。</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token comment\">// Secretly the stream is saying: \"whoa, whoa! hang on, this is way too much!\"</span>\n<span class=\"token comment\">// Data will begin to build up on the read-side of the data buffer as</span>\n<span class=\"token comment\">// `write` tries to keep up with the incoming data flow.</span>\ninp<span class=\"token punctuation\">.</span><span class=\"token function\">pipe</span><span class=\"token punctuation\">(</span>gzip<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">pipe</span><span class=\"token punctuation\">(</span>outputFile<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>这就是背压机制很重要的原因。如果背压系统不存在，这个过程将耗尽系统的内存，严重减缓其他的过程，并垄断大部分系统资源直到完成。</p>\n<p>结局如下:</p>\n<ul>\n<li>放慢所有其他现有流程</li>\n<li>一个非常劳累过度的垃圾收集器</li>\n<li>内存耗尽</li>\n</ul>\n<p>在以下示例中，我们将取出<code class=\"language-text\">.write()</code> 函数的返回值并将其更改为 true，这有效地禁用了Node.js内核中的背压支持。在任何对“修改”二进制文件的引用中，我们都在讨论如何运行没有 <code class=\"language-text\">return ret;</code> 的节点二进制 (node binary) 文件线，而替换为 <code class=\"language-text\">return true</code> ;</p>\n<h2>过量的垃圾收集</h2>\n<p>让我们看看一个快速的基准。使用上面的同一个例子，我们进行了几次试验，以获得两个二进制文件的中位时间。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">   trial (#)  | `node` binary (ms) | modified `node` binary (ms)\n=================================================================\n      1       |      56924         |           55011\n      2       |      52686         |           55869\n      3       |      59479         |           54043\n      4       |      54473         |           55229\n      5       |      52933         |           59723\n=================================================================\naverage time: |      55299         |           55975</code></pre></div>\n<p>两者都花费一分钟左右的时间，所以根本没什么区别，但让我们仔细观察一下，以确认我们的猜测是否正确。我们使用 Linux 工具 <code class=\"language-text\">dtrace</code> 来评估V8垃圾收集器的情况。</p>\n<p>GC（垃圾回收器）测量的时间表示垃圾收集器完成的单次扫描的完整周期的时间间隔：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">approx. time (ms) | GC (ms) | modified GC (ms)\n=================================================\n          0       |    0    |      0\n          1       |    0    |      0\n         40       |    0    |      2\n        170       |    3    |      1\n        300       |    3    |      1\n\n         *             *           *\n         *             *           *\n         *             *           *\n\n      39000       |    6    |     26\n      42000       |    6    |     21\n      47000       |    5    |     32\n      50000       |    8    |     28\n      54000       |    6    |     35</code></pre></div>\n<p>虽然这两种方法的起始时间相同，并且似乎以相同的速度工作，但显然在几秒钟后使用正确工作的反压系统GC负荷会以4-8毫秒的间隔持续扩散，直到数据传输结束。</p>\n<p>但是，当背压系统不在时，V8垃圾回收系统开始拖延。正常的二进制文件在一分钟内调用GC约75次，而修改后的二进制文件只触发36次。</p>\n<p>这是由于记忆体使用量增加而累积的缓慢而渐进的债务。随着数据的传输，如果没有背压系统，每个块传输都会使用更多的内存。</p>\n<p>分配的内存越多，GC就必须在一次扫描中处理得越多。扫描越大，GC需要决定什么可以释放，并且在更大的内存空间中扫描分离的指针会消耗更多的计算能力。</p>\n<h2>内存耗尽</h2>\n<p>为了确定每个二进制文件的内存消耗，我们为每个进程分别设定了<code class=\"language-text\">/usr/bin/time -lp sudo ./node ./backpressure-example/zlib.js</code>。</p>\n<p>这是正常二进制的输出：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Respecting the return value of .write()\n=============================================\nreal        58.88\nuser        56.79\nsys          8.79\n  87810048  maximum resident set size\n         0  average shared memory size\n         0  average unshared data size\n         0  average unshared stack size\n     19427  page reclaims\n      3134  page faults\n         0  swaps\n         5  block input operations\n       194  block output operations\n         0  messages sent\n         0  messages received\n         1  signals received\n        12  voluntary context switches\n    666037  involuntary context switches</code></pre></div>\n<p>虚拟内存占用的最大字节大小约为87.81 mb。 现在改变 <code class=\"language-text\">.write()</code> 函数的返回值，我们得到：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Without respecting the return value of .write():\n==================================================\nreal        54.48\nuser        53.15\nsys          7.43\n1524965376  maximum resident set size\n         0  average shared memory size\n         0  average unshared data size\n         0  average unshared stack size\n    373617  page reclaims\n      3139  page faults\n         0  swaps\n        18  block input operations\n       199  block output operations\n         0  messages sent\n         0  messages received\n         1  signals received\n        25  voluntary context switches\n    629566  involuntary context switches</code></pre></div>\n<p>虚拟内存占用的最大字节大小约为1.52 gb。</p>\n<p>如果没有适当的 Stream backpressure，分配的内存空间就会增加一个数量级 - 这是同一过程之间的巨大差异！</p>\n<p>这个实验展示了 Node.js 的背压机制是如何针对您的计算系统优化和具有成本效益的。现在，让我们分析一下它的工作原理！</p>\n<h2>背压是如何解决这些问题的?</h2>\n<p>有不同的功能将数据从一个进程传输到另一个进程。在Node.js中，有一个名为<code class=\"language-text\">.pipe()</code>的内部内置函数。还有其他的软件包也可以使用！但最终，在这个过程的基本层面上，我们有两个独立的组件：数据源和消费者。</p>\n<p>当从源调用<code class=\"language-text\">.pipe()</code>时，它向消费者发出信号，告知有数据要传输。管道功能有助于为事件触发器设置适当的背压闭合。</p>\n<p>在Node.js中，源是可读流，而消费者是可写流（这两者可以与双工或转换流互换，但对于本指南而言，这是超出范围的）。</p>\n<p>触发背压的时刻可以精确地缩小到Writable的<code class=\"language-text\">.write()</code>函数的返回值。当然，这个返回值由几个条件决定。</p>\n<p>在数据缓冲区已超过<code class=\"language-text\">highWaterMark</code>或写入队列当前正忙的任何情况下，<code class=\"language-text\">.write()</code>将返回<code class=\"language-text\">false</code>。</p>\n<p>当返回错误值时，背压系统启动。它将暂停传入的可读流发送任何数据并等待消费者再次准备就绪。清空数据缓冲区后，将发出<code class=\"language-text\">.drain()</code>事件并恢复传入的数据流。</p>\n<p>队列完成后，背压将允许再次发送数据。正在使用的内存空间将自行释放并为下一批数据做好准备。</p>\n<p>这有效地允许在任何给定时间为<code class=\"language-text\">.pipe()</code>函数使用固定数量的内存。没有内存泄漏，没有无限缓冲，垃圾收集器只需要处理内存中的一个区域！</p>\n<p>那么，如果背压如此重要，为什么你（可能）没有听说过它？那么答案很简单：Node.js自动完成所有这些。</p>\n<p>太棒了！但是当我们试图理解如何实现我们自己的自定义流时也不是那么好。</p>\n<p>注意：在大多数机器中，有一个字节大小决定缓冲区何时已满（这将在不同的机器上有所不同）。 Node.js允许您设置自己的自定义highWaterMark，但通常，默认设置为16kb（对于objectMode流，为16384或16）。在某些情况下，您可能需要提高该值，但请谨慎行事！</p>\n<h2><code class=\"language-text\">.pipe()</code>的生命周期</h2>\n<p>为了更好地理解背压，下面是一个可读流的生命周期的流程图，该流被导入到可写流中：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">                                                     +===================+\n                         x--&gt;  Piping functions   +--&gt;   src.pipe(dest)  |\n                         x     are set up during     |===================|\n                         x     the .pipe method.     |  Event callbacks  |\n  +===============+      x                           |-------------------|\n  |   Your Data   |      x     They exist outside    | .on(&#39;close&#39;, cb)  |\n  +=======+=======+      x     the data flow, but    | .on(&#39;data&#39;, cb)   |\n          |              x     importantly attach    | .on(&#39;drain&#39;, cb)  |\n          |              x     events, and their     | .on(&#39;unpipe&#39;, cb) |\n+---------v---------+    x     respective callbacks. | .on(&#39;error&#39;, cb)  |\n|  Readable Stream  +----+                           | .on(&#39;finish&#39;, cb) |\n+-^-------^-------^-+    |                           | .on(&#39;end&#39;, cb)    |\n  ^       |       ^      |                           +-------------------+\n  |       |       |      |\n  |       ^       |      |\n  ^       ^       ^      |    +-------------------+         +=================+\n  ^       |       ^      +----&gt;  Writable Stream  +---------&gt;  .write(chunk)  |\n  |       |       |           +-------------------+         +=======+=========+\n  |       |       |                                                 |\n  |       ^       |                              +------------------v---------+\n  ^       |       +-&gt; if (!chunk)                |    Is this chunk too big?  |\n  ^       |       |     emit .end();             |    Is the queue busy?      |\n  |       |       +-&gt; else                       +-------+----------------+---+\n  |       ^       |     emit .write();                   |                |\n  |       ^       ^                                   +--v---+        +---v---+\n  |       |       ^-----------------------------------&lt;  No  |        |  Yes  |\n  ^       |                                           +------+        +---v---+\n  ^       |                                                               |\n  |       ^               emit .pause();          +=================+     |\n  |       ^---------------^-----------------------+  return false;  &lt;-----+---+\n  |                                               +=================+         |\n  |                                                                           |\n  ^            when queue is empty     +============+                         |\n  ^------------^-----------------------&lt;  Buffering |                         |\n               |                       |============|                         |\n               +&gt; emit .drain();       |  ^Buffer^  |                         |\n               +&gt; emit .resume();      +------------+                         |\n                                       |  ^Buffer^  |                         |\n                                       +------------+   add chunk to queue    |\n                                       |            &lt;---^---------------------&lt;\n                                       +============+</code></pre></div>\n<p>注意：如果您正在设置一个管道以将几个流链接在一起来操纵数据，那么您很可能会实现Transform流。</p>\n<p>在这种情况下，来自可读流的输出将输入到Transform中，并将流入Writable。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Readable.pipe(Transformable).pipe(Writable);</code></pre></div>\n<p>背压将自动应用，但请注意转换流的输入和输出<code class=\"language-text\">highWaterMark</code>可能会被操纵，并会影响反压系统。</p>\n<h2>背压指南</h2>\n<p>由于Node.js v0.10，Stream类提供了使用这些函数（<code class=\"language-text\">._read()和._write()</code>）的下划线版本来修改<code class=\"language-text\">.read()</code>或<code class=\"language-text\">.write()</code>的行为的功能。 。</p>\n<p>有关于实现可读流和实现可写流的指导文件。我们假设你已经阅读了这些内容，下一节将更深入一点。</p>\n<h2>实现自定义流时遵守的规则</h2>\n<p><code class=\"language-text\">Stream</code>的黄金法则是始终尊重背压。最佳实践的构成是非矛盾的做法。只要你小心避免与内部背压支持相冲突的行为，就可以确定你正在遵循良好的做法。</p>\n<p>一般来说:</p>\n<ol>\n<li>如果没有询问，请不要使用<code class=\"language-text\">.push()</code>。</li>\n<li>永远不要在返回false后调用<code class=\"language-text\">.write()</code>，而是等待’drain’。</li>\n<li>Streams在不同的Node.js版本和您使用的库之间进行更改。要小心注意并测试一下。</li>\n</ol>\n<p>注意：关于第3点，构建浏览器流的非常有用的包是<code class=\"language-text\">readable-stream</code>。 Rodd Vagg撰写了一篇很棒的博客文章，描述了这个库的实用性。简而言之，它为可读流提供了一种自动优雅降级，并支持旧版本的浏览器和Node.js.</p>\n<h2>可读流的特定规则</h2>\n<p>到目前为止，我们已经了解了<code class=\"language-text\">.write()</code>如何影响背压，并将重点放在<code class=\"language-text\">Writable</code>流上。由于Node.js的功能，数据在技术上从可读流向下游流向可写。但是，正如我们可以在数据，物质或能量的任何传输中观察到的那样，源与目标一样重要，可读流对于如何处理背压至关重要。</p>\n<p>这两个进程都依赖于另一个进行有效的通信，如果<code class=\"language-text\">Readable</code>忽略了当<code class=\"language-text\">Writable</code>流要求它停止发送数据时，它可能与<code class=\"language-text\">.write()</code>的返回值不正确时一样有问题。</p>\n<p>因此，在尊重<code class=\"language-text\">.write()</code>返回时，我们还必须尊重<code class=\"language-text\">._read()</code>方法中使用的<code class=\"language-text\">.push()</code>的返回值。如果<code class=\"language-text\">.push()</code>返回一个假值，则该流将停止从源读取。否则，它将继续而不会暂停。</p>\n<p>这有个使用<code class=\"language-text\">.push()</code>的反例</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">// This is problematic as it completely ignores return value from push\n// which may be a signal for backpressure from the destination stream!\nclass MyReadable extends Readable {\n  _read(size) {\n    let chunk;\n    while (null !== (chunk = getNextChunk())) {\n      this.push(chunk);\n    }\n  }\n}</code></pre></div>\n<p>另外，从定制流的外部来看，忽视背压是非常重要的。在这个良好实践的反例中，应用程序的代码在数据可用时强制数据（由<code class=\"language-text\">.data</code>事件发送信号）：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">// This ignores the backpressure mechanisms Node.js has set in place,\n// and unconditionally pushes through data, regardless if the\n// destination stream is ready for it or not.\nreadable.on(&#39;data&#39;, (data) =&gt;\n  writable.write(data)\n);</code></pre></div>\n<h2>可写流的特定规则</h2>\n<p>回想一下<code class=\"language-text\">.write()</code>可能会根据某些条件返回true或false。幸运的是，在构建我们自己的可写流时，流状态机将处理我们的回调并确定何时处理背压并为我们优化数据流。</p>\n<p>但是，当我们想直接使用Writable时，我们必须尊重<code class=\"language-text\">.write()</code>返回值并密切注意这些条件：</p>\n<ul>\n<li>如果写队列忙，.<code class=\"language-text\">write()</code>将返回false。</li>\n<li>如果数据块太大，<code class=\"language-text\">.write()</code>将返回false（该值由变量highWaterMark指示）。</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">// This writable is invalid because of the async nature of JavaScript callbacks.\n// Without a return statement for each callback prior to the last,\n// there is a great chance multiple callbacks will be called.\nclass MyWritable extends Writable {\n  _write(chunk, encoding, callback) {\n    if (chunk.toString().indexOf(&#39;a&#39;) &gt;= 0)\n      callback();\n    else if (chunk.toString().indexOf(&#39;b&#39;) &gt;= 0)\n      callback();\n    callback();\n  }\n}\n\n// The proper way to write this would be:\n    if (chunk.contains(&#39;a&#39;))\n      return callback();\n    else if (chunk.contains(&#39;b&#39;))\n      return callback();\n    callback();</code></pre></div>\n<p>在实现<code class=\"language-text\">._writev()</code>时还需要注意一些事项。该函数与<code class=\"language-text\">.cork()</code>结合使用，但写入时常见错误：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">// Using .uncork() twice here makes two calls on the C++ layer, rendering the\n// cork/uncork technique useless.\nws.cork();\nws.write(&#39;hello &#39;);\nws.write(&#39;world &#39;);\nws.uncork();\n\nws.cork();\nws.write(&#39;from &#39;);\nws.write(&#39;Matteo&#39;);\nws.uncork();\n\n// The correct way to write this is to utilize process.nextTick(), which fires\n// on the next event loop.\nws.cork();\nws.write(&#39;hello &#39;);\nws.write(&#39;world &#39;);\nprocess.nextTick(doUncork, ws);\n\nws.cork();\nws.write(&#39;from &#39;);\nws.write(&#39;Matteo&#39;);\nprocess.nextTick(doUncork, ws);\n\n// as a global function\nfunction doUncork(stream) {\n  stream.uncork();\n}</code></pre></div>\n<p><code class=\"language-text\">.cork()</code>可以被调用多次，我们只需要小心调用<code class=\"language-text\">.uncork()</code>相同的次数，使其再次流动。</p>\n<h2>结论</h2>\n<p>Streams是Node.js中经常使用的模块。它们对于内部结构非常重要，对于开发人员来说，它们可以跨Node.js模块生态系统进行扩展和连接。</p>\n<p>希望您现在能够排除故障，安全地编写您自己的可写和可读流的背景，并与同事和朋友分享您的知识。</p>\n<p>在使用Node.js构建应用程序时，请务必阅读有关其他API函数的Stream的更多信息，以帮助改进和释放您的流功能。</p>","frontmatter":{"title":"Node.js Streams 中的背压(backpressure)","date":"July 03, 2018","categories":"弱鸡之路"}}},"pageContext":{"slug":"/Backpressure/","previous":{"fields":{"slug":"/JavaScript-ES2018-ES9-新增标准/"},"frontmatter":{"title":"JavaScript ES2018/ES9 新增标准"}},"next":{"fields":{"slug":"/学习的意义/"},"frontmatter":{"title":"学习的意义"}}}}}